---
title: "LLM Selection"
sidebarTitle: "LLM"
description: "Choose the AI model that powers your agent's understanding and responses."
---

The LLM (Large Language Model) is the brain behind your agent. It's what understands caller intent, generates natural responses, and decides what to do next. Different models offer different tradeoffs between intelligence, speed, and cost.

---

## Available Models

Atoms supports multiple LLM providers and models. Choose based on your use case:

| Model | Best For | Characteristics |
|-------|----------|-----------------|
| **GPT-4.1** | Complex conversations, nuanced understanding | Most capable, higher cost, slightly slower |
| **GPT-4o-mini** | Balanced performance | Good capability, moderate cost, fast |
| **Albert** | High-volume, simple interactions | Fast, cost-effective, handles routine conversations well |

---

## How to Choose

### Choose GPT-4.1 when:
- Conversations are complex or nuanced
- You need the best possible understanding
- Accuracy matters more than cost
- Callers may ask unexpected or difficult questions

### Choose GPT-4o-mini when:
- You want a balance of capability and cost
- Conversations are moderately complex
- Speed matters but so does quality

### Choose Albert when:
- You're handling high call volumes
- Conversations follow predictable patterns
- Speed and cost are primary concerns
- You're running outbound campaigns at scale

---

## Model Settings

Beyond choosing a model, you can configure behavior:

### Temperature

Controls how "creative" vs "predictable" the model behaves.

| Value | Behavior | Best For |
|-------|----------|----------|
| **0.0 - 0.3** | Consistent, factual | Support, FAQ, compliance |
| **0.4 - 0.6** | Balanced | General conversations |
| **0.7 - 1.0** | Creative, varied | Sales, engagement |

Lower temperature = more predictable responses. Higher temperature = more variety and creativity.

### Max Tokens

Limits response length. For voice agents, keep this moderate (100-300 tokens). Long responses lose caller attention.

---

## Impact on Agent Behavior

The LLM affects:

**Understanding**
How well the agent interprets what callers mean, even when they speak unclearly or use unexpected phrasing.

**Response Quality**
How natural, helpful, and appropriate the agent's responses are.

**Prompt Following**
How closely the agent follows your instructions in the system prompt.

**Edge Case Handling**
How well the agent handles unusual situations not explicitly covered in your prompt.

---

<Accordion title="Best Practices">
**Start with GPT-4.1, optimize later.** Build and test with the best model first. Once your agent works well, try cheaper models to see if quality holds up.

**Match model to use case.** A complex sales conversation needs more intelligence than "Press 1 for billing, press 2 for support."

**Monitor conversations.** Review conversation logs to see if the model is understanding callers correctly. Frequent misunderstandings might mean you need a more capable model.

**Consider cost at scale.** For outbound campaigns with thousands of calls, model cost adds up. Test with Albert to see if it handles your specific use case.
</Accordion>

---

## Next Steps

<CardGroup cols={2}>
  <Card title="Language Settings" icon="globe" href="/platform/building-agents/configuration/agent-settings/language-settings">
    Configure language and localization
  </Card>
  <Card title="Voice Selection" icon="microphone" href="/platform/building-agents/configuration/agent-settings/voice-selection">
    Choose how your agent sounds
  </Card>
</CardGroup>
