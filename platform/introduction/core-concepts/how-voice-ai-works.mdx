---
title: "How Voice AI Works"
sidebarTitle: "How Voice AI Works"
description: "Understand the technology behind real-time voice conversations with AI."
---

Voice AI agents seem like magic â€” you speak, they understand, they respond naturally. But under the hood, there's a sophisticated pipeline making it all happen in real-time. Understanding this helps you build better agents.

---

## The Voice AI Pipeline

Every voice conversation flows through three core stages:

```
ðŸŽ¤ Speech-to-Text â†’ ðŸ§  LLM Processing â†’ ðŸ”Š Text-to-Speech
```

### 1. Speech-to-Text (STT)

When a caller speaks, their audio is captured and converted to text. This happens in real-time, word by word, so the system can start processing before the caller finishes speaking.

**Key factors:**
- Accuracy of transcription
- Handling accents and background noise
- Speed of processing

### 2. LLM Processing

The transcribed text goes to a language model that:
- Understands the intent behind words
- Considers conversation context
- Generates an appropriate response
- Follows your configured prompts and rules

This is where your agent's "brain" lives â€” the prompts you write, the knowledge base you attach, and the logic you define.

### 3. Text-to-Speech (TTS)

The model's text response is converted back to natural-sounding speech. Modern TTS systems produce remarkably human-like voices with appropriate intonation, pacing, and emotion.

---

## Why Latency Matters

In voice conversations, **latency** is everything. Humans expect responses within 200-400ms â€” any longer feels unnatural.

Traditional large language models struggle here:
- Processing takes 1-2+ seconds
- Users experience awkward pauses
- Conversations feel robotic

**Atoms solves this with Small Language Models:**
- 100ms streaming responses
- Start speaking before processing completes
- Natural conversation rhythm

---

## Real-Time Considerations

Building voice AI is different from chatbots:

| Chatbots | Voice AI |
|----------|----------|
| User can re-read responses | One-time delivery |
| Can send long paragraphs | Must be concise |
| User types carefully | User speaks naturally (with ums, interruptions) |
| Response time less critical | Every millisecond matters |
| Can show buttons/links | Voice-only interface |

**Implications for your agents:**
- Keep responses short (under 30 words ideal)
- Anticipate interruptions
- Design for ears, not eyes
- Handle "um", "uh", and restarts gracefully

---

## How Atoms Handles It

Atoms manages the entire pipeline so you can focus on what your agent should say:

1. **Telephony Integration** â€” Connects to phone networks
2. **Real-time STT** â€” Fast, accurate transcription
3. **Optimized LLM** â€” Small models, big speed
4. **Quality TTS** â€” Natural-sounding voices
5. **Turn Management** â€” Handles interruptions and pauses

You configure the conversation logic. We handle the infrastructure.

---

## What's Next

<CardGroup cols={2}>
  <Card title="Agent Types" icon="robot" href="/platform/introduction/core-concepts/agent-types">
    Choose the right agent type for your use case
  </Card>
  <Card title="Key Terms" icon="book" href="/platform/introduction/core-concepts/key-terms">
    Learn the vocabulary of voice AI
  </Card>
</CardGroup>
