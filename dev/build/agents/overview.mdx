---
title: "Agents"
sidebarTitle: "Overview"
description: "The brain of your voice application."
---

An **Agent** is the core component that powers conversational AI in the Atoms SDK. It's the "brain" that listens to what users say, thinks about how to respond, and speaks back—all in real-time.

## What is an Agent?

In Atoms, an agent is implemented as an `OutputAgentNode`—a specialized node that handles the complete conversation loop:

1. **Listen** — Receives transcribed speech from the user
2. **Think** — Processes the input with an LLM to generate a response
3. **Speak** — Streams the response as audio back to the user

This happens continuously, creating a natural back-and-forth conversation just like talking to a human.

## Why Atoms Agents?

| Feature | Description |
|---------|-------------|
| **Real-Time Streaming** | Responses start playing while the LLM is still generating. No waiting—conversation feels instant. |
| **Interruption Handling** | When users speak mid-response, the agent stops and listens. No overlapping speech. |
| **Context Management** | Conversation history maintained automatically. Your agent remembers everything. |
| **Tool Calling** | Execute functions mid-conversation—check databases, call APIs, book appointments. |
| **Multi-Provider LLM** | Use OpenAI, Anthropic, or bring your own model. Switch without code changes. |
| **Production Ready** | Deploy with one command. Handle thousands of concurrent calls. |

## What's Next

<CardGroup cols={2}>
  <Card title="Configuration" icon="sliders" href="/dev/build/agents/agent-configuration/overview">
    Set up prompts, LLM settings, and voice configuration.
  </Card>
  <Card title="Tools & Functions" icon="wrench" href="/dev/build/agents/tools-functions/overview">
    Give your agent the ability to take actions and fetch data.
  </Card>

  <Card title="Testing & Debugging" icon="bug" href="/dev/build/agents/debugging-testing/overview">
    Test locally and debug common issues.
  </Card>
</CardGroup>
