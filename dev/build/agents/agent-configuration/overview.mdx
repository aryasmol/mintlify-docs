---
title: "Configuration"
sidebarTitle: "Overview"
description: "Setting up the brain of your agent."
---

**Configuration** is how you define your agent's behavior—which LLM it uses, how it responds, and what voice it speaks with. Get this right and your agent feels natural. Get it wrong and users will notice.

## What is Configuration?

Every agent needs three things configured:

1. **LLM Settings** — Which model to use, temperature, streaming behavior
2. **Prompts** — System instructions that define personality and constraints
3. **Voice** — Speed, tone, and which TTS model to use

The SDK provides sensible defaults, so you can start simple and tune later.

## Key Settings

| Setting | What It Controls |
|---------|------------------|
| **Model** | GPT-4o, Claude, Llama, or your own |
| **Temperature** | 0.0 = deterministic, 1.0 = creative |
| **Streaming** | Essential for real-time voice (always use `stream=True`) |
| **System Prompt** | The personality, rules, and context |
| **Voice ID** | Which synthesized voice to use |

## What's Next

<CardGroup cols={2}>
  <Card title="Prompts" icon="message" href="/dev/build/agents/agent-configuration/prompts">
    Craft effective system prompts that define behavior.
  </Card>
  <Card title="LLM Settings" icon="brain" href="/dev/build/agents/agent-configuration/llm-settings">
    Model selection, temperature, and provider configuration.
  </Card>
  <Card title="Voice Settings" icon="microphone" href="/dev/build/agents/agent-configuration/voice-settings">
    Configure TTS voice, speed, and prosody.
  </Card>
  <Card title="Bring Your Own Model" icon="server" href="/dev/build/agents/agent-configuration/byom">
    Run local models with Ollama, vLLM, or custom servers.
  </Card>
</CardGroup>
